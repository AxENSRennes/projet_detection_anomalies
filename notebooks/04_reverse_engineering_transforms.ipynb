{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reverse Engineering Transforms Analysis\n",
    "\n",
    "This notebook explores the advanced signal transforms proposed in the Anomaly Reverse Engineering Report:\n",
    "\n",
    "1. **Nonlinear Power Transforms (x², x⁴)** - Unmask phase structure of digital modulations\n",
    "2. **Symbol-Lagged Correlation (τ ≈ 3.4)** - Highlight phase relationships between symbols\n",
    "3. **Instantaneous Frequency Analysis (dφ/dt)** - Reveal frequency shift patterns\n",
    "4. **Cyclostationary Feature Extraction (SCF)** - Exploit periodic statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.fft import fft, fftfreq\n",
    "from scipy.stats import kurtosis, skew\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, f1_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from data_utils import load_train_data, load_test_anomalies, filter_by_snr, create_binary_labels\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "plt.rcParams['font.size'] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "print(\"Loading data...\")\n",
    "train_signals, train_labels, train_snr = load_train_data()\n",
    "test_signals, test_labels, test_snr = load_test_anomalies()\n",
    "\n",
    "# Filter SNR=0 from training (not present in test)\n",
    "train_signals, train_labels, train_snr = filter_by_snr(\n",
    "    train_signals, train_labels, train_snr, [10, 20, 30]\n",
    ")\n",
    "\n",
    "# Binary labels for test\n",
    "test_binary = create_binary_labels(test_labels)\n",
    "\n",
    "print(f\"Train: {len(train_signals)} samples, Classes: {np.unique(train_labels)}\")\n",
    "print(f\"Test: {len(test_signals)} samples, Classes: {np.unique(test_labels)}\")\n",
    "print(f\"Test anomalies: {test_binary.sum()} ({100*test_binary.mean():.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iq_to_complex(sig):\n",
    "    \"\"\"Convert (N, 2) IQ signal to complex array.\"\"\"\n",
    "    return sig[:, 0] + 1j * sig[:, 1]\n",
    "\n",
    "# Get sample indices for each class\n",
    "def get_class_samples(labels, signals, n_samples=5):\n",
    "    \"\"\"Get sample indices for each class.\"\"\"\n",
    "    samples = {}\n",
    "    for c in np.unique(labels):\n",
    "        idx = np.where(labels == c)[0][:n_samples]\n",
    "        samples[c] = signals[idx]\n",
    "    return samples\n",
    "\n",
    "train_samples = get_class_samples(train_labels, train_signals, n_samples=50)\n",
    "test_samples = get_class_samples(test_labels, test_signals, n_samples=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Nonlinear Power Transforms (x², x⁴)\n",
    "\n",
    "For BPSK (Class 6), x² maps {0, π} states to 0 rad → spectral line at 2× carrier.\n",
    "For QPSK (Class 8), x⁴ collapses four quadrants → spectral line at 4× carrier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_power_transform_features(sig):\n",
    "    \"\"\"\n",
    "    Compute features from nonlinear power transforms.\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with features from x², x⁴ transforms\n",
    "    \"\"\"\n",
    "    x = iq_to_complex(sig)\n",
    "    n = len(x)\n",
    "    \n",
    "    # Square transform: y = x²\n",
    "    x2 = x ** 2\n",
    "    spec_x2 = np.abs(fft(x2))[:n//2]\n",
    "    spec_x2_norm = spec_x2 / (spec_x2.sum() + 1e-10)\n",
    "    \n",
    "    # Quad transform: y = x⁴\n",
    "    x4 = x ** 4\n",
    "    spec_x4 = np.abs(fft(x4))[:n//2]\n",
    "    spec_x4_norm = spec_x4 / (spec_x4.sum() + 1e-10)\n",
    "    \n",
    "    features = {\n",
    "        # x² spectrum features\n",
    "        'x2_spec_max': spec_x2.max(),\n",
    "        'x2_spec_peak_ratio': spec_x2.max() / (spec_x2.mean() + 1e-10),\n",
    "        'x2_spec_kurtosis': kurtosis(spec_x2),\n",
    "        'x2_spec_entropy': -np.sum(spec_x2_norm * np.log(spec_x2_norm + 1e-10)),\n",
    "        \n",
    "        # x⁴ spectrum features  \n",
    "        'x4_spec_max': spec_x4.max(),\n",
    "        'x4_spec_peak_ratio': spec_x4.max() / (spec_x4.mean() + 1e-10),\n",
    "        'x4_spec_kurtosis': kurtosis(spec_x4),\n",
    "        'x4_spec_entropy': -np.sum(spec_x4_norm * np.log(spec_x4_norm + 1e-10)),\n",
    "        \n",
    "        # Phase after transforms\n",
    "        'x2_phase_std': np.std(np.angle(x2)),\n",
    "        'x4_phase_std': np.std(np.angle(x4)),\n",
    "        \n",
    "        # Amplitude after transforms\n",
    "        'x2_amp_std': np.std(np.abs(x2)),\n",
    "        'x4_amp_std': np.std(np.abs(x4)),\n",
    "    }\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize power transforms for each class\n",
    "fig, axes = plt.subplots(3, 9, figsize=(18, 10))\n",
    "\n",
    "all_classes = list(range(6)) + [6, 7, 8]\n",
    "class_names = ['C0', 'C1', 'C2', 'C3', 'C4', 'C5', 'A6 (BPSK)', 'A7 (Const)', 'A8 (QPSK)']\n",
    "\n",
    "for i, c in enumerate(all_classes):\n",
    "    if c < 6:\n",
    "        sig = train_samples[c][0]\n",
    "    else:\n",
    "        sig = test_samples[c][0]\n",
    "    \n",
    "    x = iq_to_complex(sig)\n",
    "    n = len(x)\n",
    "    freqs = fftfreq(n)[:n//2]\n",
    "    \n",
    "    # Original spectrum\n",
    "    spec = np.abs(fft(x))[:n//2]\n",
    "    axes[0, i].semilogy(freqs, spec, 'b-', lw=0.5)\n",
    "    axes[0, i].set_title(class_names[i], fontsize=9)\n",
    "    if i == 0:\n",
    "        axes[0, i].set_ylabel('|FFT(x)|')\n",
    "    \n",
    "    # x² spectrum\n",
    "    x2 = x ** 2\n",
    "    spec_x2 = np.abs(fft(x2))[:n//2]\n",
    "    axes[1, i].semilogy(freqs, spec_x2, 'r-', lw=0.5)\n",
    "    if i == 0:\n",
    "        axes[1, i].set_ylabel('|FFT(x²)|')\n",
    "    \n",
    "    # x⁴ spectrum\n",
    "    x4 = x ** 4\n",
    "    spec_x4 = np.abs(fft(x4))[:n//2]\n",
    "    axes[2, i].semilogy(freqs, spec_x4, 'g-', lw=0.5)\n",
    "    if i == 0:\n",
    "        axes[2, i].set_ylabel('|FFT(x⁴)|')\n",
    "    axes[2, i].set_xlabel('Freq')\n",
    "\n",
    "plt.suptitle('Nonlinear Power Transforms: Spectral Analysis', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots_power_transforms.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved: plots_power_transforms.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute power transform features for all signals\n",
    "print(\"Computing power transform features...\")\n",
    "\n",
    "def extract_features_for_dataset(signals):\n",
    "    features_list = []\n",
    "    for sig in signals:\n",
    "        features_list.append(compute_power_transform_features(sig))\n",
    "    feature_names = list(features_list[0].keys())\n",
    "    features = np.array([[f[n] for n in feature_names] for f in features_list])\n",
    "    return features, feature_names\n",
    "\n",
    "train_power_feats, power_feat_names = extract_features_for_dataset(train_signals)\n",
    "test_power_feats, _ = extract_features_for_dataset(test_signals)\n",
    "\n",
    "print(f\"Features: {power_feat_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate AUC for each power transform feature\n",
    "print(\"\\n=== Power Transform Features AUC ===\")\n",
    "power_aucs = {}\n",
    "for i, name in enumerate(power_feat_names):\n",
    "    try:\n",
    "        auc = roc_auc_score(test_binary, test_power_feats[:, i])\n",
    "        # Try inverted if AUC < 0.5\n",
    "        if auc < 0.5:\n",
    "            auc = 1 - auc\n",
    "        power_aucs[name] = auc\n",
    "        print(f\"{name:25s}: AUC = {auc:.3f}\")\n",
    "    except:\n",
    "        print(f\"{name:25s}: ERROR\")\n",
    "\n",
    "best_power = max(power_aucs, key=power_aucs.get)\n",
    "print(f\"\\nBest power transform feature: {best_power} (AUC={power_aucs[best_power]:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Symbol-Lagged Correlation (τ ≈ 3.4)\n",
    "\n",
    "Using the retro-engineered symbol rate, apply lagged conjugate product:\n",
    "$$y(t) = x(t) \\cdot x^*(t - \\tau) \\quad \\text{where } \\tau \\approx 3.4$$\n",
    "\n",
    "For Constant Envelope signals (Class 7), phase remains stable during symbol duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_symbol_lag_features(sig, tau_values=[3, 4, 5, 10, 20]):\n",
    "    \"\"\"\n",
    "    Compute features from symbol-lagged correlation.\n",
    "    \n",
    "    y(t) = x(t) * conj(x(t-tau))\n",
    "    \"\"\"\n",
    "    x = iq_to_complex(sig)\n",
    "    features = {}\n",
    "    \n",
    "    for tau in tau_values:\n",
    "        # Lagged conjugate product\n",
    "        y = x[tau:] * np.conj(x[:-tau])\n",
    "        \n",
    "        # Phase of product = phase difference\n",
    "        phase_diff = np.angle(y)\n",
    "        \n",
    "        # Features from this lag\n",
    "        features[f'lag{tau}_phase_std'] = np.std(phase_diff)\n",
    "        features[f'lag{tau}_phase_mean'] = np.abs(np.mean(phase_diff))\n",
    "        features[f'lag{tau}_amp_std'] = np.std(np.abs(y))\n",
    "        features[f'lag{tau}_amp_mean'] = np.mean(np.abs(y))\n",
    "        \n",
    "        # Phase stability: count \"plateaus\" where phase is stable\n",
    "        phase_changes = np.abs(np.diff(phase_diff))\n",
    "        stable_fraction = np.mean(phase_changes < 0.1)\n",
    "        features[f'lag{tau}_stable_frac'] = stable_fraction\n",
    "        \n",
    "        # Kurtosis of phase changes (should be high for discrete modulations)\n",
    "        features[f'lag{tau}_phase_change_kurtosis'] = kurtosis(phase_changes)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize symbol-lagged correlation\n",
    "fig, axes = plt.subplots(3, 9, figsize=(18, 10))\n",
    "\n",
    "tau = 3  # Close to symbol rate of 3.4\n",
    "\n",
    "for i, c in enumerate(all_classes):\n",
    "    if c < 6:\n",
    "        sig = train_samples[c][0]\n",
    "    else:\n",
    "        sig = test_samples[c][0]\n",
    "    \n",
    "    x = iq_to_complex(sig)\n",
    "    y = x[tau:] * np.conj(x[:-tau])\n",
    "    phase_diff = np.angle(y)\n",
    "    \n",
    "    # Time slice\n",
    "    t_slice = slice(0, 500)\n",
    "    \n",
    "    # Phase difference over time\n",
    "    axes[0, i].plot(phase_diff[t_slice], 'b-', lw=0.5)\n",
    "    axes[0, i].set_title(class_names[i], fontsize=9)\n",
    "    axes[0, i].set_ylim(-np.pi, np.pi)\n",
    "    if i == 0:\n",
    "        axes[0, i].set_ylabel(f'Phase diff (τ={tau})')\n",
    "    \n",
    "    # Histogram of phase differences\n",
    "    axes[1, i].hist(phase_diff, bins=50, density=True, alpha=0.7)\n",
    "    if i == 0:\n",
    "        axes[1, i].set_ylabel('Phase diff dist')\n",
    "    \n",
    "    # IQ plot of y = x(t) * conj(x(t-tau))\n",
    "    axes[2, i].scatter(y.real[::10], y.imag[::10], s=1, alpha=0.3)\n",
    "    axes[2, i].set_aspect('equal')\n",
    "    if i == 0:\n",
    "        axes[2, i].set_ylabel('y = x·x*(t-τ)')\n",
    "\n",
    "plt.suptitle(f'Symbol-Lagged Correlation Analysis (τ={tau})', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots_symbol_lag.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved: plots_symbol_lag.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute symbol lag features\n",
    "print(\"Computing symbol-lagged correlation features...\")\n",
    "\n",
    "def extract_lag_features(signals):\n",
    "    features_list = []\n",
    "    for sig in signals:\n",
    "        features_list.append(compute_symbol_lag_features(sig))\n",
    "    feature_names = list(features_list[0].keys())\n",
    "    features = np.array([[f[n] for n in feature_names] for f in features_list])\n",
    "    return features, feature_names\n",
    "\n",
    "train_lag_feats, lag_feat_names = extract_lag_features(train_signals)\n",
    "test_lag_feats, _ = extract_lag_features(test_signals)\n",
    "\n",
    "# Evaluate AUCs\n",
    "print(\"\\n=== Symbol-Lag Features AUC ===\")\n",
    "lag_aucs = {}\n",
    "for i, name in enumerate(lag_feat_names):\n",
    "    try:\n",
    "        auc = roc_auc_score(test_binary, test_lag_feats[:, i])\n",
    "        if auc < 0.5:\n",
    "            auc = 1 - auc\n",
    "        lag_aucs[name] = auc\n",
    "        print(f\"{name:30s}: AUC = {auc:.3f}\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "best_lag = max(lag_aucs, key=lag_aucs.get)\n",
    "print(f\"\\nBest symbol-lag feature: {best_lag} (AUC={lag_aucs[best_lag]:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Instantaneous Frequency Analysis (dφ/dt)\n",
    "\n",
    "$$f_{inst} = \\frac{1}{2\\pi} \\frac{d\\phi}{dt}$$\n",
    "\n",
    "FSK variants (Class 7?) show discrete, stable frequency levels (\"staircase\" patterns).\n",
    "PSK classes show erratic spikes during transitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_inst_freq_features(sig):\n",
    "    \"\"\"\n",
    "    Compute instantaneous frequency features.\n",
    "    \"\"\"\n",
    "    x = iq_to_complex(sig)\n",
    "    \n",
    "    # Unwrap phase to avoid discontinuities\n",
    "    phase = np.unwrap(np.angle(x))\n",
    "    \n",
    "    # Instantaneous frequency = derivative of phase\n",
    "    inst_freq = np.diff(phase) / (2 * np.pi)\n",
    "    \n",
    "    # Features\n",
    "    features = {\n",
    "        'if_mean': np.mean(inst_freq),\n",
    "        'if_std': np.std(inst_freq),\n",
    "        'if_kurtosis': kurtosis(inst_freq),\n",
    "        'if_skew': skew(inst_freq),\n",
    "        'if_min': np.min(inst_freq),\n",
    "        'if_max': np.max(inst_freq),\n",
    "        'if_range': np.max(inst_freq) - np.min(inst_freq),\n",
    "        'if_median': np.median(inst_freq),\n",
    "        'if_iqr': np.percentile(inst_freq, 75) - np.percentile(inst_freq, 25),\n",
    "    }\n",
    "    \n",
    "    # Detect \"staircase\" patterns (discrete frequency levels)\n",
    "    # Quantize to detect levels\n",
    "    n_levels = len(np.unique(np.round(inst_freq, 3)))\n",
    "    features['if_n_levels'] = n_levels\n",
    "    \n",
    "    # Histogram-based entropy\n",
    "    hist, _ = np.histogram(inst_freq, bins=50, density=True)\n",
    "    hist = hist / (hist.sum() + 1e-10)\n",
    "    features['if_entropy'] = -np.sum(hist * np.log(hist + 1e-10))\n",
    "    \n",
    "    # Frequency transitions (detect sharp changes)\n",
    "    freq_diff = np.abs(np.diff(inst_freq))\n",
    "    features['if_diff_std'] = np.std(freq_diff)\n",
    "    features['if_diff_max'] = np.max(freq_diff)\n",
    "    features['if_spike_count'] = np.sum(freq_diff > 0.1)  # Count spikes\n",
    "    features['if_stable_frac'] = np.mean(freq_diff < 0.01)  # Fraction of stable regions\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize instantaneous frequency\n",
    "fig, axes = plt.subplots(3, 9, figsize=(18, 10))\n",
    "\n",
    "for i, c in enumerate(all_classes):\n",
    "    if c < 6:\n",
    "        sig = train_samples[c][0]\n",
    "    else:\n",
    "        sig = test_samples[c][0]\n",
    "    \n",
    "    x = iq_to_complex(sig)\n",
    "    phase = np.unwrap(np.angle(x))\n",
    "    inst_freq = np.diff(phase) / (2 * np.pi)\n",
    "    \n",
    "    t_slice = slice(0, 500)\n",
    "    \n",
    "    # Phase over time\n",
    "    axes[0, i].plot(phase[t_slice], 'b-', lw=0.5)\n",
    "    axes[0, i].set_title(class_names[i], fontsize=9)\n",
    "    if i == 0:\n",
    "        axes[0, i].set_ylabel('Unwrapped Phase')\n",
    "    \n",
    "    # Instantaneous frequency\n",
    "    axes[1, i].plot(inst_freq[t_slice], 'r-', lw=0.5)\n",
    "    axes[1, i].set_ylim(-0.3, 0.3)\n",
    "    if i == 0:\n",
    "        axes[1, i].set_ylabel('Inst. Freq')\n",
    "    \n",
    "    # Histogram of inst freq\n",
    "    axes[2, i].hist(inst_freq, bins=50, density=True, alpha=0.7, range=(-0.3, 0.3))\n",
    "    if i == 0:\n",
    "        axes[2, i].set_ylabel('Inst. Freq Dist')\n",
    "\n",
    "plt.suptitle('Instantaneous Frequency Analysis (dφ/dt)', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots_inst_freq_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved: plots_inst_freq_analysis.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute instantaneous frequency features\n",
    "print(\"Computing instantaneous frequency features...\")\n",
    "\n",
    "def extract_if_features(signals):\n",
    "    features_list = []\n",
    "    for sig in signals:\n",
    "        features_list.append(compute_inst_freq_features(sig))\n",
    "    feature_names = list(features_list[0].keys())\n",
    "    features = np.array([[f[n] for n in feature_names] for f in features_list])\n",
    "    return features, feature_names\n",
    "\n",
    "train_if_feats, if_feat_names = extract_if_features(train_signals)\n",
    "test_if_feats, _ = extract_if_features(test_signals)\n",
    "\n",
    "# Evaluate AUCs\n",
    "print(\"\\n=== Instantaneous Frequency Features AUC ===\")\n",
    "if_aucs = {}\n",
    "for i, name in enumerate(if_feat_names):\n",
    "    try:\n",
    "        vals = test_if_feats[:, i]\n",
    "        vals = np.nan_to_num(vals, nan=0, posinf=1e6, neginf=-1e6)\n",
    "        auc = roc_auc_score(test_binary, vals)\n",
    "        if auc < 0.5:\n",
    "            auc = 1 - auc\n",
    "        if_aucs[name] = auc\n",
    "        print(f\"{name:25s}: AUC = {auc:.3f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"{name:25s}: ERROR - {e}\")\n",
    "\n",
    "best_if = max(if_aucs, key=if_aucs.get)\n",
    "print(f\"\\nBest instantaneous freq feature: {best_if} (AUC={if_aucs[best_if]:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Cyclostationary Feature Extraction (SCF)\n",
    "\n",
    "Radio signals exhibit cyclostationary properties - statistics vary periodically with symbol rate.\n",
    "Compute spectrum of instantaneous power |x(t)|² and look for peaks at cyclic frequency α = 1/3.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cyclo_features(sig, expected_symbol_rate=3.4):\n",
    "    \"\"\"\n",
    "    Compute cyclostationary features.\n",
    "    \n",
    "    Look for periodic patterns in the signal statistics at the symbol rate.\n",
    "    \"\"\"\n",
    "    x = iq_to_complex(sig)\n",
    "    n = len(x)\n",
    "    \n",
    "    # Instantaneous power\n",
    "    power = np.abs(x) ** 2\n",
    "    \n",
    "    # Spectrum of instantaneous power (reveals cyclic frequencies)\n",
    "    power_spec = np.abs(fft(power - power.mean()))[:n//2]\n",
    "    freqs = fftfreq(n)[:n//2]\n",
    "    \n",
    "    # Expected cyclic frequency\n",
    "    alpha = 1.0 / expected_symbol_rate\n",
    "    \n",
    "    features = {}\n",
    "    \n",
    "    # Look for peak at expected cyclic frequency\n",
    "    alpha_idx = int(alpha * n)\n",
    "    window = 5\n",
    "    \n",
    "    if alpha_idx < len(power_spec) - window:\n",
    "        features['cyclo_peak_at_alpha'] = power_spec[alpha_idx-window:alpha_idx+window].max()\n",
    "        features['cyclo_peak_ratio'] = features['cyclo_peak_at_alpha'] / (power_spec.mean() + 1e-10)\n",
    "    else:\n",
    "        features['cyclo_peak_at_alpha'] = 0\n",
    "        features['cyclo_peak_ratio'] = 0\n",
    "    \n",
    "    # Overall spectral features of power\n",
    "    features['power_spec_max'] = power_spec.max()\n",
    "    features['power_spec_std'] = power_spec.std()\n",
    "    features['power_spec_kurtosis'] = kurtosis(power_spec)\n",
    "    \n",
    "    # Find dominant cyclic frequency\n",
    "    peak_idx = np.argmax(power_spec[10:]) + 10  # Skip DC component\n",
    "    features['dominant_cyclo_freq'] = freqs[peak_idx] if peak_idx < len(freqs) else 0\n",
    "    \n",
    "    # ACF of power (reveals symbol period)\n",
    "    power_centered = power - power.mean()\n",
    "    acf = np.correlate(power_centered, power_centered, mode='full')\n",
    "    acf = acf[len(acf)//2:]\n",
    "    acf = acf / (acf[0] + 1e-10)\n",
    "    \n",
    "    # Find first significant peak in ACF (symbol period)\n",
    "    peaks, properties = signal.find_peaks(acf[5:100], height=0.05, distance=2)\n",
    "    if len(peaks) > 0:\n",
    "        features['acf_power_first_peak'] = peaks[0] + 5\n",
    "        features['acf_power_first_peak_height'] = properties['peak_heights'][0]\n",
    "    else:\n",
    "        features['acf_power_first_peak'] = 0\n",
    "        features['acf_power_first_peak_height'] = 0\n",
    "    \n",
    "    # Squared signal spectrum (for BPSK detection)\n",
    "    x2 = x ** 2\n",
    "    x2_spec = np.abs(fft(x2))[:n//2]\n",
    "    features['x2_cyclo_peak'] = x2_spec.max()\n",
    "    features['x2_cyclo_ratio'] = x2_spec.max() / (x2_spec.mean() + 1e-10)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize cyclostationary features\n",
    "fig, axes = plt.subplots(3, 9, figsize=(18, 10))\n",
    "\n",
    "for i, c in enumerate(all_classes):\n",
    "    if c < 6:\n",
    "        sig = train_samples[c][0]\n",
    "    else:\n",
    "        sig = test_samples[c][0]\n",
    "    \n",
    "    x = iq_to_complex(sig)\n",
    "    n = len(x)\n",
    "    \n",
    "    # Instantaneous power\n",
    "    power = np.abs(x) ** 2\n",
    "    power_centered = power - power.mean()\n",
    "    \n",
    "    # Spectrum of power\n",
    "    power_spec = np.abs(fft(power_centered))[:n//2]\n",
    "    freqs = fftfreq(n)[:n//2]\n",
    "    \n",
    "    # ACF of power\n",
    "    acf = np.correlate(power_centered, power_centered, mode='full')\n",
    "    acf = acf[len(acf)//2:]\n",
    "    acf = acf / (acf[0] + 1e-10)\n",
    "    \n",
    "    # Power over time\n",
    "    axes[0, i].plot(power[:200], 'b-', lw=0.5)\n",
    "    axes[0, i].set_title(class_names[i], fontsize=9)\n",
    "    if i == 0:\n",
    "        axes[0, i].set_ylabel('|x(t)|²')\n",
    "    \n",
    "    # Spectrum of power\n",
    "    axes[1, i].semilogy(freqs[:200], power_spec[:200], 'r-', lw=0.5)\n",
    "    axes[1, i].axvline(1/3.4, color='g', linestyle='--', alpha=0.5, label='α=1/3.4')\n",
    "    if i == 0:\n",
    "        axes[1, i].set_ylabel('Power Spectrum')\n",
    "    \n",
    "    # ACF of power\n",
    "    axes[2, i].plot(acf[:100], 'g-', lw=0.5)\n",
    "    axes[2, i].axhline(0, color='k', linestyle='-', alpha=0.3)\n",
    "    if i == 0:\n",
    "        axes[2, i].set_ylabel('ACF(|x|²)')\n",
    "\n",
    "plt.suptitle('Cyclostationary Analysis: Power Periodicity', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots_cyclostationary.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved: plots_cyclostationary.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cyclostationary features\n",
    "print(\"Computing cyclostationary features...\")\n",
    "\n",
    "def extract_cyclo_features(signals):\n",
    "    features_list = []\n",
    "    for sig in signals:\n",
    "        features_list.append(compute_cyclo_features(sig))\n",
    "    feature_names = list(features_list[0].keys())\n",
    "    features = np.array([[f[n] for n in feature_names] for f in features_list])\n",
    "    return features, feature_names\n",
    "\n",
    "train_cyclo_feats, cyclo_feat_names = extract_cyclo_features(train_signals)\n",
    "test_cyclo_feats, _ = extract_cyclo_features(test_signals)\n",
    "\n",
    "# Evaluate AUCs\n",
    "print(\"\\n=== Cyclostationary Features AUC ===\")\n",
    "cyclo_aucs = {}\n",
    "for i, name in enumerate(cyclo_feat_names):\n",
    "    try:\n",
    "        vals = test_cyclo_feats[:, i]\n",
    "        vals = np.nan_to_num(vals, nan=0, posinf=1e6, neginf=-1e6)\n",
    "        auc = roc_auc_score(test_binary, vals)\n",
    "        if auc < 0.5:\n",
    "            auc = 1 - auc\n",
    "        cyclo_aucs[name] = auc\n",
    "        print(f\"{name:30s}: AUC = {auc:.3f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"{name:30s}: ERROR - {e}\")\n",
    "\n",
    "best_cyclo = max(cyclo_aucs, key=cyclo_aucs.get)\n",
    "print(f\"\\nBest cyclostationary feature: {best_cyclo} (AUC={cyclo_aucs[best_cyclo]:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Combined Analysis: All Transform Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all features\n",
    "print(\"Combining all transform features...\")\n",
    "\n",
    "# Combine feature arrays\n",
    "train_all_feats = np.hstack([train_power_feats, train_lag_feats, train_if_feats, train_cyclo_feats])\n",
    "test_all_feats = np.hstack([test_power_feats, test_lag_feats, test_if_feats, test_cyclo_feats])\n",
    "\n",
    "# Combine feature names\n",
    "all_feat_names = power_feat_names + lag_feat_names + if_feat_names + cyclo_feat_names\n",
    "\n",
    "print(f\"Total features: {len(all_feat_names)}\")\n",
    "print(f\"Train shape: {train_all_feats.shape}\")\n",
    "print(f\"Test shape: {test_all_feats.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all AUCs and rank\n",
    "all_aucs = {**power_aucs, **lag_aucs, **if_aucs, **cyclo_aucs}\n",
    "\n",
    "# Sort by AUC\n",
    "sorted_aucs = sorted(all_aucs.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"\\n=== Top 20 Features by AUC ===\")\n",
    "print(f\"{'Rank':<5} {'Feature':<35} {'AUC':<8} {'Category'}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for rank, (name, auc) in enumerate(sorted_aucs[:20], 1):\n",
    "    if name in power_aucs:\n",
    "        cat = 'Power Transform'\n",
    "    elif name in lag_aucs:\n",
    "        cat = 'Symbol Lag'\n",
    "    elif name in if_aucs:\n",
    "        cat = 'Inst. Freq'\n",
    "    else:\n",
    "        cat = 'Cyclostationary'\n",
    "    print(f\"{rank:<5} {name:<35} {auc:.3f}    {cat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top features\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "top_features = [name for name, _ in sorted_aucs[:8]]\n",
    "\n",
    "for idx, feat_name in enumerate(top_features):\n",
    "    feat_idx = all_feat_names.index(feat_name)\n",
    "    \n",
    "    # Get values for each class\n",
    "    for c in range(9):\n",
    "        mask = test_labels == c\n",
    "        vals = test_all_feats[mask, feat_idx]\n",
    "        color = 'blue' if c < 6 else 'red'\n",
    "        label = f'C{c}' if c < 6 else f'A{c}'\n",
    "        axes[idx].hist(vals, bins=30, alpha=0.3, label=label, color=color, density=True)\n",
    "    \n",
    "    axes[idx].set_title(f'{feat_name}\\nAUC={all_aucs[feat_name]:.3f}', fontsize=9)\n",
    "    axes[idx].legend(fontsize=6, ncol=3)\n",
    "\n",
    "plt.suptitle('Top 8 Discriminative Features from Reverse Engineering Transforms', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots_top_transform_features.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved: plots_top_transform_features.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Anomaly Detection with Combined Transform Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Isolation Forest on combined features\n",
    "print(\"Training Isolation Forest on transform features...\")\n",
    "\n",
    "# Clean up NaN/Inf\n",
    "train_clean = np.nan_to_num(train_all_feats, nan=0, posinf=1e6, neginf=-1e6)\n",
    "test_clean = np.nan_to_num(test_all_feats, nan=0, posinf=1e6, neginf=-1e6)\n",
    "\n",
    "# Standardize\n",
    "scaler = StandardScaler()\n",
    "train_scaled = scaler.fit_transform(train_clean)\n",
    "test_scaled = scaler.transform(test_clean)\n",
    "\n",
    "# Train IF\n",
    "clf = IsolationForest(n_estimators=200, contamination=0.1, random_state=42, n_jobs=-1)\n",
    "clf.fit(train_scaled)\n",
    "\n",
    "# Predict\n",
    "scores = -clf.score_samples(test_scaled)  # Higher = more anomalous\n",
    "\n",
    "# Evaluate\n",
    "auc = roc_auc_score(test_binary, scores)\n",
    "print(f\"\\nOverall AUC: {auc:.3f}\")\n",
    "\n",
    "# Per-class AUC\n",
    "for c in [6, 7, 8]:\n",
    "    mask = (test_labels == c) | (test_labels < 6)\n",
    "    binary_c = (test_labels[mask] == c).astype(int)\n",
    "    auc_c = roc_auc_score(binary_c, scores[mask])\n",
    "    print(f\"Class {c} AUC: {auc_c:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best F1 threshold\n",
    "precision, recall, thresholds = precision_recall_curve(test_binary, scores)\n",
    "f1_scores = 2 * precision * recall / (precision + recall + 1e-10)\n",
    "best_idx = np.argmax(f1_scores)\n",
    "best_threshold = thresholds[best_idx] if best_idx < len(thresholds) else thresholds[-1]\n",
    "best_f1 = f1_scores[best_idx]\n",
    "\n",
    "print(f\"\\nBest F1: {best_f1:.3f}\")\n",
    "print(f\"At threshold: {best_threshold:.3f}\")\n",
    "print(f\"Precision: {precision[best_idx]:.3f}\")\n",
    "print(f\"Recall: {recall[best_idx]:.3f}\")\n",
    "\n",
    "# Per-class detection at best threshold\n",
    "predictions = (scores > best_threshold).astype(int)\n",
    "print(\"\\nPer-class detection rates:\")\n",
    "for c in [6, 7, 8]:\n",
    "    mask = test_labels == c\n",
    "    detection_rate = predictions[mask].mean()\n",
    "    print(f\"  Anomaly {c}: {100*detection_rate:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with C42 baseline from deep-deep dive\n",
    "from feature_extraction import compute_cumulants\n",
    "\n",
    "print(\"\\n=== Comparison with C42 Baseline ===\")\n",
    "\n",
    "# Compute C42 for test\n",
    "test_c42 = np.array([compute_cumulants(iq_to_complex(s))['C42'] for s in test_signals])\n",
    "\n",
    "# C42 alone AUC\n",
    "c42_auc = roc_auc_score(test_binary, test_c42)\n",
    "if c42_auc < 0.5:\n",
    "    c42_auc = 1 - c42_auc\n",
    "    test_c42 = -test_c42\n",
    "\n",
    "print(f\"C42 alone AUC: {c42_auc:.3f}\")\n",
    "print(f\"Transform features AUC: {auc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined: Transform features + C42 filter\n",
    "print(\"\\n=== Combined Approach: C42 Filter + Transform Features ===\")\n",
    "\n",
    "# C42 filter threshold\n",
    "C42_THRESHOLD = -0.35\n",
    "\n",
    "# Stage 1: C42 filter (definite normals)\n",
    "sure_normal = test_c42 < C42_THRESHOLD\n",
    "print(f\"Stage 1 - C42 < {C42_THRESHOLD}:\")\n",
    "print(f\"  Samples: {sure_normal.sum()}\")\n",
    "print(f\"  Anomalies in this group: {test_binary[sure_normal].sum()}\")\n",
    "\n",
    "# Stage 2: IF on remaining\n",
    "ambiguous = ~sure_normal\n",
    "print(f\"\\nStage 2 - Ambiguous samples: {ambiguous.sum()}\")\n",
    "\n",
    "# Train on ambiguous training samples\n",
    "train_c42 = np.array([compute_cumulants(iq_to_complex(s))['C42'] for s in train_signals])\n",
    "train_ambiguous = train_c42 >= C42_THRESHOLD\n",
    "\n",
    "scaler2 = StandardScaler()\n",
    "train_amb_scaled = scaler2.fit_transform(train_clean[train_ambiguous])\n",
    "test_amb_scaled = scaler2.transform(test_clean[ambiguous])\n",
    "\n",
    "clf2 = IsolationForest(n_estimators=200, contamination=0.4, random_state=42, n_jobs=-1)\n",
    "clf2.fit(train_amb_scaled)\n",
    "\n",
    "# Combined scores\n",
    "final_scores = np.zeros(len(test_signals))\n",
    "final_scores[sure_normal] = -10  # Definitely normal\n",
    "final_scores[ambiguous] = -clf2.score_samples(test_amb_scaled)\n",
    "\n",
    "# Evaluate combined\n",
    "combined_auc = roc_auc_score(test_binary, final_scores)\n",
    "print(f\"\\nCombined AUC: {combined_auc:.3f}\")\n",
    "\n",
    "# Best F1\n",
    "precision, recall, thresholds = precision_recall_curve(test_binary, final_scores)\n",
    "f1_scores = 2 * precision * recall / (precision + recall + 1e-10)\n",
    "best_idx = np.argmax(f1_scores)\n",
    "best_f1 = f1_scores[best_idx]\n",
    "print(f\"Best F1: {best_f1:.3f}\")\n",
    "print(f\"Precision: {precision[best_idx]:.3f}\")\n",
    "print(f\"Recall: {recall[best_idx]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Per-Anomaly Class Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-class feature comparison\n",
    "print(\"=== Per-Anomaly Class Feature Analysis ===\")\n",
    "\n",
    "for anomaly_class in [6, 7, 8]:\n",
    "    print(f\"\\n--- Anomaly Class {anomaly_class} ---\")\n",
    "    \n",
    "    # Find features that best separate this anomaly from similar known classes\n",
    "    if anomaly_class in [6, 8]:  # Similar to class 3 based on C42\n",
    "        similar_classes = [3]\n",
    "    else:  # Class 7 similar to 4, 5\n",
    "        similar_classes = [4, 5]\n",
    "    \n",
    "    # Create binary: anomaly vs similar known\n",
    "    mask_anomaly = test_labels == anomaly_class\n",
    "    mask_similar = np.isin(test_labels, similar_classes)\n",
    "    mask = mask_anomaly | mask_similar\n",
    "    \n",
    "    binary_local = test_labels[mask] == anomaly_class\n",
    "    feats_local = test_all_feats[mask]\n",
    "    \n",
    "    # Rank features\n",
    "    local_aucs = {}\n",
    "    for i, name in enumerate(all_feat_names):\n",
    "        try:\n",
    "            vals = np.nan_to_num(feats_local[:, i], nan=0, posinf=1e6, neginf=-1e6)\n",
    "            auc = roc_auc_score(binary_local, vals)\n",
    "            if auc < 0.5:\n",
    "                auc = 1 - auc\n",
    "            local_aucs[name] = auc\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Top 5 for this anomaly\n",
    "    sorted_local = sorted(local_aucs.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "    print(f\"  Best features vs classes {similar_classes}:\")\n",
    "    for name, auc in sorted_local:\n",
    "        print(f\"    {name}: AUC={auc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# 1. Feature category comparison\n",
    "ax = axes[0, 0]\n",
    "categories = ['Power\\nTransform', 'Symbol\\nLag', 'Inst.\\nFreq', 'Cyclo-\\nstationary']\n",
    "cat_aucs = [\n",
    "    max(power_aucs.values()) if power_aucs else 0,\n",
    "    max(lag_aucs.values()) if lag_aucs else 0,\n",
    "    max(if_aucs.values()) if if_aucs else 0,\n",
    "    max(cyclo_aucs.values()) if cyclo_aucs else 0\n",
    "]\n",
    "colors = ['#e74c3c', '#3498db', '#2ecc71', '#9b59b6']\n",
    "bars = ax.bar(categories, cat_aucs, color=colors)\n",
    "ax.set_ylabel('Best AUC')\n",
    "ax.set_title('Best AUC by Transform Category')\n",
    "ax.set_ylim(0.5, 1.0)\n",
    "for bar, auc in zip(bars, cat_aucs):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "            f'{auc:.3f}', ha='center', fontsize=9)\n",
    "\n",
    "# 2. ROC curve\n",
    "ax = axes[0, 1]\n",
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, _ = roc_curve(test_binary, final_scores)\n",
    "ax.plot(fpr, tpr, 'b-', lw=2, label=f'Combined (AUC={combined_auc:.3f})')\n",
    "fpr2, tpr2, _ = roc_curve(test_binary, scores)\n",
    "ax.plot(fpr2, tpr2, 'r--', lw=2, label=f'Transform only (AUC={auc:.3f})')\n",
    "ax.plot([0, 1], [0, 1], 'k--', alpha=0.5)\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('ROC Curves')\n",
    "ax.legend()\n",
    "\n",
    "# 3. Score distributions\n",
    "ax = axes[1, 0]\n",
    "ax.hist(final_scores[test_binary == 0], bins=50, alpha=0.5, label='Known (0-5)', density=True)\n",
    "ax.hist(final_scores[test_binary == 1], bins=50, alpha=0.5, label='Anomaly (6-8)', density=True)\n",
    "ax.set_xlabel('Anomaly Score')\n",
    "ax.set_ylabel('Density')\n",
    "ax.set_title('Score Distributions')\n",
    "ax.legend()\n",
    "\n",
    "# 4. Per-class detection\n",
    "ax = axes[1, 1]\n",
    "best_threshold = thresholds[best_idx] if best_idx < len(thresholds) else thresholds[-1]\n",
    "predictions = (final_scores > best_threshold).astype(int)\n",
    "\n",
    "class_rates = []\n",
    "class_labels = []\n",
    "for c in range(9):\n",
    "    mask = test_labels == c\n",
    "    if c < 6:\n",
    "        # False positive rate for known classes\n",
    "        rate = predictions[mask].mean()\n",
    "        class_labels.append(f'C{c}\\n(FP)')\n",
    "    else:\n",
    "        # True positive rate for anomalies\n",
    "        rate = predictions[mask].mean()\n",
    "        class_labels.append(f'A{c}\\n(TP)')\n",
    "    class_rates.append(rate)\n",
    "\n",
    "colors = ['blue']*6 + ['red']*3\n",
    "ax.bar(class_labels, class_rates, color=colors, alpha=0.7)\n",
    "ax.set_ylabel('Detection Rate')\n",
    "ax.set_title('Per-Class Detection Rates at Best F1 Threshold')\n",
    "ax.axhline(0.5, color='k', linestyle='--', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots_transform_summary.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved: plots_transform_summary.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"REVERSE ENGINEERING TRANSFORMS - SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n1. POWER TRANSFORMS (x², x⁴)\")\n",
    "print(f\"   Best feature: {best_power} (AUC={power_aucs[best_power]:.3f})\")\n",
    "print(\"   Insight: x² and x⁴ transforms reveal modulation structure,\")\n",
    "print(\"   but didn't significantly outperform simpler features.\")\n",
    "\n",
    "print(\"\\n2. SYMBOL-LAGGED CORRELATION (τ ≈ 3.4)\")\n",
    "print(f\"   Best feature: {best_lag} (AUC={lag_aucs[best_lag]:.3f})\")\n",
    "print(\"   Insight: Phase stability between symbols varies by modulation,\")\n",
    "print(\"   provides complementary discrimination.\")\n",
    "\n",
    "print(\"\\n3. INSTANTANEOUS FREQUENCY (dφ/dt)\")\n",
    "print(f\"   Best feature: {best_if} (AUC={if_aucs[best_if]:.3f})\")\n",
    "print(\"   Insight: IF statistics help distinguish modulation types,\")\n",
    "print(\"   if_std is particularly useful.\")\n",
    "\n",
    "print(\"\\n4. CYCLOSTATIONARY FEATURES\")\n",
    "print(f\"   Best feature: {best_cyclo} (AUC={cyclo_aucs[best_cyclo]:.3f})\")\n",
    "print(\"   Insight: Power spectrum features reveal cyclic structure,\")\n",
    "print(\"   useful for regime separation.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"OVERALL RESULTS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nTransform features alone: AUC={auc:.3f}, F1={best_f1:.3f}\")\n",
    "print(f\"Combined (C42 filter + transforms): AUC={combined_auc:.3f}\")\n",
    "print(f\"\\nTop 5 features overall:\")\n",
    "for i, (name, auc_val) in enumerate(sorted_aucs[:5], 1):\n",
    "    print(f\"  {i}. {name}: AUC={auc_val:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
